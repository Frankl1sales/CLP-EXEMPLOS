{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmSbR0ucVc42UyQfD0REcx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frankl1sales/CLP-EXEMPLOS/blob/main/BERTIMBAUTreinamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8PTqFTDqif8",
        "outputId": "d0c04a23-64fd-49db-e8b4-ac60a0a49bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorFlow1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75GxIt1SrsAE",
        "outputId": "00786545-72eb-4bc6-fb0b-3f3db775aa20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TensorFlow1\n",
            "  Downloading TensorFlow1-3.2.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting selenium (from TensorFlow1)\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TensorFlow1) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TensorFlow1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TensorFlow1) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->TensorFlow1) (1.25.2)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium->TensorFlow1) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium->TensorFlow1)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium->TensorFlow1)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->TensorFlow1) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium->TensorFlow1) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->TensorFlow1) (1.16.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->TensorFlow1) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->TensorFlow1) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->TensorFlow1) (3.6)\n",
            "Collecting outcome (from trio~=0.17->selenium->TensorFlow1)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->TensorFlow1) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->TensorFlow1) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->TensorFlow1)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->TensorFlow1) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium->TensorFlow1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: TensorFlow1\n",
            "  Building wheel for TensorFlow1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TensorFlow1: filename=TensorFlow1-3.2.0-py3-none-any.whl size=5116 sha256=70d2e3b2b21133cee44e015dec260be490c09a0aaf01cf57027954c5bb371982\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/4f/54/4f5183ac8e9d01b48c31b7c654eb0eccaf97a0ee253fc51240\n",
            "Successfully built TensorFlow1\n",
            "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium, TensorFlow1\n",
            "Successfully installed TensorFlow1-3.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.18.1 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3d2p7Ddrvz1",
        "outputId": "69567f30-91e9-4063-cacc-06cbced396f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax) (1.25.2)\n",
            "Requirement already satisfied: jax>=0.4.19 in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.23)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.9)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (1.11.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.85)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.1.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFBbXK1or8lA",
        "outputId": "1f62c6ab-306f-49bf-fbb2-968d31ec25c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.3\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.6.0\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.5.0\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.14.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        0.21.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.4\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.1\n",
            "build                            1.0.3\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.3.3\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.2.2\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.85\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.16.0\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.1\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.4\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.0\n",
            "cryptography                     42.0.5\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.3\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.8\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.9.2\n",
            "earthengine-api                  0.1.391\n",
            "easydict                         1.12\n",
            "ecos                             2.0.13\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.2.0\n",
            "fastai                           2.7.14\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.19.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.13.1\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.8.1\n",
            "folium                           0.14.0\n",
            "fonttools                        4.49.0\n",
            "frozendict                       2.4.0\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.6.4\n",
            "gdown                            4.7.3\n",
            "geemap                           0.31.0\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.4.0\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.0\n",
            "google-cloud-aiplatform          1.42.1\n",
            "google-cloud-bigquery            3.12.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.14.2\n",
            "google-cloud-language            2.13.2\n",
            "google-cloud-resource-manager    1.12.2\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.3.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.0\n",
            "googleapis-common-protos         1.62.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.0\n",
            "grpcio                           1.62.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h11                              0.14.0\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.43\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.20.3\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   7.1.0\n",
            "idna                             3.6\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               7.0.1\n",
            "importlib_resources              6.1.2\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.3\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.23\n",
            "jaxlib                           0.4.23+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.3\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.3\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.1\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.10\n",
            "kaggle                           1.5.16\n",
            "kagglehub                        0.1.9\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2023.1067\n",
            "Markdown                         3.5.2\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.9.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.2.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.58.1\n",
            "numexpr                          2.9.0\n",
            "numpy                            1.25.2\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.9.0.80\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.9\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "outcome                          1.3.0.post0\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.3.8\n",
            "param                            2.0.2\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.1\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pins                             0.8.4\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.2.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.4.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.1\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.43\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.23.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.5.1\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         2.6.3\n",
            "pydantic_core                    2.16.3\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.0.0\n",
            "pyparsing                        3.1.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.4\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2023.4\n",
            "pyviz_comms                      3.0.1\n",
            "PyWavelets                       1.5.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.33.0\n",
            "regex                            2023.12.25\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.7.0\n",
            "rpds-py                          0.18.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.2\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.4.post1\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "selenium                         4.18.1\n",
            "Send2Trash                       1.8.2\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.3\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.7.4\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.8\n",
            "sphinxcontrib-devhelp            1.0.6\n",
            "sphinxcontrib-htmlhelp           2.0.5\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.7\n",
            "sphinxcontrib-serializinghtml    1.1.10\n",
            "SQLAlchemy                       2.0.27\n",
            "sqlglot                          19.9.0\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.1\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.11.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.15.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.4\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.36.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.23.0\n",
            "TensorFlow1                      3.2.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.0\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-keras                         2.15.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.3\n",
            "threadpoolctl                    3.3.0\n",
            "tifffile                         2024.2.12\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.15.2\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.1\n",
            "torch                            2.1.0+cu121\n",
            "torchaudio                       2.1.0+cu121\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu121\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.2\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.38.1\n",
            "trio                             0.24.0\n",
            "trio-websocket                   0.11.1\n",
            "triton                           2.1.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2024.1.0.20240203\n",
            "types-setuptools                 69.1.0.20240223\n",
            "typing_extensions                4.10.0\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.3.4\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.7.0\n",
            "Werkzeug                         3.0.1\n",
            "wheel                            0.42.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "wsproto                          1.2.0\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.0.3\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.1\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.37\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjeHUOTtsOnp",
        "outputId": "6cf6a403-eabd-479d-b956-2db886fe4495"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: flax\n",
            "Version: 0.8.1\n",
            "Summary: Flax: A neural network library for JAX designed for flexibility\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Flax team <flax-dev@google.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: jax, msgpack, numpy, optax, orbax-checkpoint, PyYAML, rich, tensorstore, typing-extensions\n",
            "Required-by: dopamine-rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxFUl1jsVct",
        "outputId": "6b1c041a-aa1d-4d27-d6eb-0f13284241ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paSsp7_1vOkf",
        "outputId": "a29d1a35-2d48-432d-ac7a-9e09b7433230"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
        "\n",
        "# Carregue o tokenizador e o modelo de máscara BERT para a linguagem portuguesa\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "model = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glsVluKvsd-3",
        "outputId": "accd2cb2-078c-4cfd-ff73-ad2e501cbdc2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie o pipeline usando o modelo BERT\n",
        "pipe = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Teste preenchendo a máscara em uma sentença\n",
        "results = pipe('Tinha uma [MASK] no meio do caminho.')\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4Npr8hJziLU",
        "outputId": "522c3ede-1f5d-4999-b40e-b48dbb59c336"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.1428779512643814, 'token': 5028, 'token_str': 'pedra', 'sequence': 'Tinha uma pedra no meio do caminho.'}\n",
            "{'score': 0.06213385611772537, 'token': 7411, 'token_str': 'árvore', 'sequence': 'Tinha uma árvore no meio do caminho.'}\n",
            "{'score': 0.05514984950423241, 'token': 5675, 'token_str': 'estrada', 'sequence': 'Tinha uma estrada no meio do caminho.'}\n",
            "{'score': 0.029918842017650604, 'token': 1105, 'token_str': 'casa', 'sequence': 'Tinha uma casa no meio do caminho.'}\n",
            "{'score': 0.025660419836640358, 'token': 3466, 'token_str': 'cruz', 'sequence': 'Tinha uma cruz no meio do caminho.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparação dos Dados"
      ],
      "metadata": {
        "id": "Mn0G44b-PNrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conjunto de Dados de Texto\n",
        "\n",
        "conjunto de dados que contenha sentenças com palavras mascaradas\n"
      ],
      "metadata": {
        "id": "XeXdbYOSPQVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de criação de um conjunto de dados fictício\n",
        "dataset = [\n",
        "    \"O pássaro canta durante a manhã.\",\n",
        "    \"O Opelisco está no centro da cidade.\",\n",
        "    \"As aranhas são animais fascinantes.\",\n",
        "    \"Ela pedala todos os dias.\",\n",
        "    \"A paisagem está cheia de estrelas.\"\n",
        "]\n",
        "\n",
        "# Visualizando o conjunto de dados\n",
        "for sentence in dataset:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyJsFGTxS0bA",
        "outputId": "3298365d-ac26-42bf-c132-28c4eb519f8c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O pássaro canta durante a manhã.\n",
            "O Opelisco está no centro da cidade.\n",
            "As aranhas são animais fascinantes.\n",
            "Ela pedala todos os dias.\n",
            "A paisagem está cheia de estrelas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def mask_words(sentence, mask_prob=0.15):\n",
        "    # Divide a sentença em palavras\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Escolhe aleatoriamente palavras para mascarar\n",
        "    masked_indices = random.sample(range(len(words)), int(len(words) * mask_prob))\n",
        "\n",
        "    # Substitui as palavras selecionadas por [MASK]\n",
        "    for idx in masked_indices:\n",
        "        words[idx] = \"[MASK]\"\n",
        "\n",
        "    # Junta as palavras novamente em uma sentença\n",
        "    masked_sentence = \" \".join(words)\n",
        "\n",
        "    return masked_sentence\n"
      ],
      "metadata": {
        "id": "FzI8KOutpYry"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um novo conjunto de dados com palavras mascaradas\n",
        "masked_dataset = [mask_words(sentence) for sentence in dataset]\n",
        "\n",
        "# Visualizando o conjunto de dados mascarado\n",
        "for sentence in masked_dataset:\n",
        "    print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qAo7hhCqBw1",
        "outputId": "f8fadc30-e1e9-40f3-86c8-7566842952a8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O [MASK] canta durante a [MASK].\n",
            "[MASK] está no centro da cidade.\n",
            "As [MASK] são animais fascinantes.\n",
            "Ela [MASK] todos os dias.\n",
            "A [MASK] está cheia de estrelas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pré-processamento dos Dados"
      ],
      "metadata": {
        "id": "0vgECtIqO5O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização das Sentenças\n",
        "Utilizando a biblioteca **transformers** para tokenizar as setenças"
      ],
      "metadata": {
        "id": "iNViULcDO8rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregue o tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Exemplo de sentenças\n",
        "sentences = masked_dataset\n",
        "\n",
        "# Tokenize as sentenças e substitua uma palavra por [MASK]\n",
        "tokenized_sentences = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "print(\"Sentenças tokenizadas:\", tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmKK2wxpKnQ-",
        "outputId": "5619cd8c-a0fd-49fc-f7d7-29d58894a13d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentenças tokenizadas: {'input_ids': tensor([[  101,   231,   103,  8954,   726,   123,   103,   119,   102,     0],\n",
            "        [  101,   103,   698,   202,  1997,   180,   651,   119,   102,     0],\n",
            "        [  101,   510,   103,   453,  3155,  8573,   387,   358,   119,   102],\n",
            "        [  101,  1660,   103,   944,   259,  1564,   119,   102,     0,     0],\n",
            "        [  101,   177,   103,   698, 13086,   125,  4425,   119,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A saída \"Sentenças tokenizadas\" que você mostrou é um dicionário contendo três tensores:\n",
        "\n",
        "**input_ids**: IDs dos tokens tokenizados. Cada lista representa uma sentença, onde os IDs dos tokens estão presentes.\n",
        "\n",
        "**token_type_ids**: IDs que indicam a qual segmento (se é o primeiro ou segundo) cada token pertence.\n",
        "\n",
        "**attention_mask**: Máscara de atenção indicando quais tokens são reais e quais são preenchidos (0 indica que o token é preenchido, 1 indica um token real)."
      ],
      "metadata": {
        "id": "Wn4USCygVmOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representações Numéricas\n",
        "Convertendo as setenças tokenizadas em representações numéricas"
      ],
      "metadata": {
        "id": "E9vc1VcEPeoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acesse os IDs dos tokens\n",
        "input_ids = tokenized_sentences[\"input_ids\"]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjH1I6VKPrC0",
        "outputId": "5786a2c9-aa2c-4161-c373-cc442814d6c6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,   231,   103,  8954,   726,   123,   103,   119,   102,     0],\n",
            "        [  101,   103,   698,   202,  1997,   180,   651,   119,   102,     0],\n",
            "        [  101,   510,   103,   453,  3155,  8573,   387,   358,   119,   102],\n",
            "        [  101,  1660,   103,   944,   259,  1564,   119,   102,     0,     0],\n",
            "        [  101,   177,   103,   698, 13086,   125,  4425,   119,   102,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = tokenized_sentences['attention_mask']\n",
        "print(attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTRj7OyDYpza",
        "outputId": "dad022f4-3697-46c4-a45c-31d93719529e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = input_ids.clone()\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NmGU7kKZSdm",
        "outputId": "ec4f2411-85ed-4d7c-8890-f26c74569f02"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,   231,   103,  8954,   726,   123,   103,   119,   102,     0],\n",
            "        [  101,   103,   698,   202,  1997,   180,   651,   119,   102,     0],\n",
            "        [  101,   510,   103,   453,  3155,  8573,   387,   358,   119,   102],\n",
            "        [  101,  1660,   103,   944,   259,  1564,   119,   102,     0,     0],\n",
            "        [  101,   177,   103,   698, 13086,   125,  4425,   119,   102,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregamento do Modelo"
      ],
      "metadata": {
        "id": "C0DuMIgAQUq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento do Modelo BERT Pré-treinado\n",
        "Usando a biblioteca **transformers** para carregar o modelo **BERTIMBAU**\n"
      ],
      "metadata": {
        "id": "Oxckw7ucQYGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, pipeline\n",
        "\n",
        "# Carregue o modelo BERTIMBAU pré-treinado\n",
        "model = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5olSDqvVQudf",
        "outputId": "c347b4e0-f5f2-4b04-985d-3bd7d64e72e6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste do Modelo BERTIMBAU"
      ],
      "metadata": {
        "id": "4wG14mHps8OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie o pipeline usando o modelo BERT\n",
        "pipe = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Teste preenchendo a máscara em uma sentença\n",
        "results = pipe(masked_dataset)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_QIOO0Mq8z0",
        "outputId": "bba52d70-eac7-4114-9323-df1875f7613f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'score': 0.2047966867685318, 'token': 939, 'token_str': 'grupo', 'sequence': '[CLS] O grupo canta durante a [MASK]. [SEP]'}, {'score': 0.05897710844874382, 'token': 4249, 'token_str': 'cantor', 'sequence': '[CLS] O cantor canta durante a [MASK]. [SEP]'}, {'score': 0.05372759699821472, 'token': 1788, 'token_str': 'público', 'sequence': '[CLS] O público canta durante a [MASK]. [SEP]'}, {'score': 0.033051278442144394, 'token': 4672, 'token_str': 'casal', 'sequence': '[CLS] O casal canta durante a [MASK]. [SEP]'}, {'score': 0.029878173023462296, 'token': 16647, 'token_str': 'coral', 'sequence': '[CLS] O coral canta durante a [MASK]. [SEP]'}], [{'score': 0.0865575522184372, 'token': 2954, 'token_str': 'noite', 'sequence': '[CLS] O [MASK] canta durante a noite. [SEP]'}, {'score': 0.08304905891418457, 'token': 1119, 'token_str': 'música', 'sequence': '[CLS] O [MASK] canta durante a música. [SEP]'}, {'score': 0.08017916977405548, 'token': 4689, 'token_str': 'apresentação', 'sequence': '[CLS] O [MASK] canta durante a apresentação. [SEP]'}, {'score': 0.07250738143920898, 'token': 8729, 'token_str': 'sessão', 'sequence': '[CLS] O [MASK] canta durante a sessão. [SEP]'}, {'score': 0.05334842950105667, 'token': 4939, 'token_str': 'festa', 'sequence': '[CLS] O [MASK] canta durante a festa. [SEP]'}]]\n",
            "[{'score': 0.30451032519340515, 'token': 787, 'token_str': 'Ele', 'sequence': 'Ele está no centro da cidade.'}, {'score': 0.2939959466457367, 'token': 1660, 'token_str': 'Ela', 'sequence': 'Ela está no centro da cidade.'}, {'score': 0.03300603851675987, 'token': 192, 'token_str': 'E', 'sequence': 'E está no centro da cidade.'}, {'score': 0.02036995068192482, 'token': 2542, 'token_str': 'Não', 'sequence': 'Não está no centro da cidade.'}, {'score': 0.02014634758234024, 'token': 1986, 'token_str': 'Também', 'sequence': 'Também está no centro da cidade.'}]\n",
            "[{'score': 0.3737546503543854, 'token': 7230, 'token_str': 'aves', 'sequence': 'As aves são animais fascinantes.'}, {'score': 0.31258314847946167, 'token': 21451, 'token_str': 'abelhas', 'sequence': 'As abelhas são animais fascinantes.'}, {'score': 0.037806641310453415, 'token': 2968, 'token_str': 'flores', 'sequence': 'As flores são animais fascinantes.'}, {'score': 0.036617569625377655, 'token': 2943, 'token_str': 'crianças', 'sequence': 'As crianças são animais fascinantes.'}, {'score': 0.025020020082592964, 'token': 1101, 'token_str': 'pessoas', 'sequence': 'As pessoas são animais fascinantes.'}]\n",
            "[{'score': 0.11591465026140213, 'token': 3379, 'token_str': 'aparece', 'sequence': 'Ela aparece todos os dias.'}, {'score': 0.07817459106445312, 'token': 5896, 'token_str': 'muda', 'sequence': 'Ela muda todos os dias.'}, {'score': 0.061358414590358734, 'token': 1359, 'token_str': 'volta', 'sequence': 'Ela volta todos os dias.'}, {'score': 0.04237845167517662, 'token': 19994, 'token_str': 'acorda', 'sequence': 'Ela acorda todos os dias.'}, {'score': 0.04022625461220741, 'token': 3539, 'token_str': 'vem', 'sequence': 'Ela vem todos os dias.'}]\n",
            "[{'score': 0.25259554386138916, 'token': 2690, 'token_str': 'Terra', 'sequence': 'A Terra está cheia de estrelas.'}, {'score': 0.13772466778755188, 'token': 7856, 'token_str': 'Lua', 'sequence': 'A Lua está cheia de estrelas.'}, {'score': 0.1128385066986084, 'token': 13943, 'token_str': 'lua', 'sequence': 'A lua está cheia de estrelas.'}, {'score': 0.08587346971035004, 'token': 2480, 'token_str': 'terra', 'sequence': 'A terra está cheia de estrelas.'}, {'score': 0.06311270594596863, 'token': 1069, 'token_str': 'vida', 'sequence': 'A vida está cheia de estrelas.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento\n",
        "O objetivo principal ao treinar um modelo BERT para prever palavras mascaradas é capacitá-lo a entender o contexto das palavras em uma frase. Durante o treinamento, algumas palavras nas sentenças de treinamento são mascaradas (substituídas pelo token [MASK]), e o modelo é treinado para prever essas palavras mascaradas com base no contexto fornecido pelas palavras ao redor."
      ],
      "metadata": {
        "id": "t8bKcyq2RAgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do BERTIMBAU"
      ],
      "metadata": {
        "id": "wcBDVxcyREkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from transformers import AutoModelForMaskedLM, AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "5nZUo-AfRJgb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar DataLoader\n",
        "dataset1 = TensorDataset(input_ids, attention_mask, labels)\n",
        "train_size = int(0.8 * len(dataset1))\n",
        "val_size = len(dataset1) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset1, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "OLChNelSY7dE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar o modelo\n",
        "model = AutoModelForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 7\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80SUUAQoZaH1",
        "outputId": "245dda14-acd4-42b2-fa99-1d3ebf961a8f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, optimizer, scheduler, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Descompactar o batch\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Saídas do modelo\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        average_loss = total_loss / len(train_dataloader)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}')"
      ],
      "metadata": {
        "id": "86pa_APGZgiO"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_dataloader, optimizer, scheduler, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6ptQbCK_bcE",
        "outputId": "ac18a3a5-9e8a-4a0e-95b2-3a57b4b29cf0"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7, Average Loss: 2.314837336540222\n",
            "Epoch 2/7, Average Loss: 2.2978105545043945\n",
            "Epoch 3/7, Average Loss: 2.287902593612671\n",
            "Epoch 4/7, Average Loss: 2.3278708457946777\n",
            "Epoch 5/7, Average Loss: 2.2926270961761475\n",
            "Epoch 6/7, Average Loss: 2.3373337984085083\n",
            "Epoch 7/7, Average Loss: 2.304298162460327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste de Modelo\n",
        "Será utilizado o modelo treinado para prever novas palavras"
      ],
      "metadata": {
        "id": "8pL3HXQ2zaei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "XDG1DnOO3s8k"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.brasildefato.com.br/2024/03/01/bolsonarismo-busca-sobrevida-politica-ao-reforcar-o-populismo-religioso\"\n",
        "\n",
        "# Fazendo a requisição HTTP\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificando se a requisição foi bem-sucedida (código 200)\n",
        "if response.status_code == 200:\n",
        "    # Criando um objeto BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Encontrando o elemento que contém o texto da notícia\n",
        "    text_element = soup.find('div', class_='text-content')\n",
        "\n",
        "    # Extraindo o texto se o elemento for encontrado\n",
        "    if text_element:\n",
        "        # Encontrando todos os parágrafos dentro do elemento\n",
        "        paragraphs = text_element.find_all('p')\n",
        "\n",
        "        # Iterando pelos parágrafos e imprimindo o texto\n",
        "        for paragraph in paragraphs:\n",
        "            print(paragraph.get_text())\n",
        "\n",
        "    else:\n",
        "        print(\"Elemento de texto não encontrado.\")\n",
        "else:\n",
        "    print(\"Erro na requisição. Código de status:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW0n5sDH1vQH",
        "outputId": "6f769b77-7b01-4d0d-ee6d-2baeaaf424da"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A manifestação em defesa do ex-presidente Jair Bolsonaro (PL), no último domingo(25), em São Paulo, reforçou a tática política adotada pela extrema direita no Brasil do chamado populismo religioso e demonstrou que o bolsonarismo busca sobrevida eleitoral alimentando a base cristã. O ato serviu para manter os apoiadores ligados ao conservadorismo nacional coesos e apontar o tom da disputa política nas eleições municipais. \n",
            "A manifestação, convocada logo após o cerco da Polícia Federal ao ex-presidente, contou com a presença de quatro governadores, deputados e prefeitos, além dos pastores Magno Malta (que também é senador pelo Espírito Santo) e Silas Malafaia, este último apontado como um dos financiadores.\n",
            "\r\n",
            "Acuado pelas investigações da PF e pela inelegibilidade imposta pelo Tribunal Superior Eleitoral (TSE), Bolsonaro saiu em sua própria defesa, tentou suavizar o seu comportamento anterior e sugeriu passar uma borracha no passado.\n",
            "No lugar dos ataques aos ministros do Supremo Tribunal Federal e as demais instituições da república, um apelo à anistia aos envolvidos no oito de janeiro e a defesa do Estado Democrático de Direito.\n",
            "\r\n",
            "O ato na Avenida Paulista acabou tomado pela estética religiosa, com repetidas citações bíblicas, louvor cristão como trilha sonora e discurso de dois pastores evangélicos. \n",
            "\"Não está ali colocada uma crítica à economia lá do Haddad, não tem questões de educação, saúde, tudo. Todo discurso ali está de alguma maneira vinculado à narrativa fundamentalista\", explicou Delana Corazza, pesquisadora do Instituto Tricontinental que estuda os evangélicos e trabalho de base.\n",
            "Coube ao governador do estado de São Paulo, Tarcísio de Freitas (Republicanos), recuperar supostos feitos do governo Bolsonaro e aproximar, minimamente, o evento de algo mais materialista e laico.\n",
            "\"O que nós percebemos do populismo religioso é o acionamento de símbolos, de formas, de performances, especialmente de ruas, de manifestações das lideranças nas mídias e em espaços públicos, e que atendam, não exclusivamente, ao público religioso, mas que atendam ao público maior com características de uma religiosidade que beira o fanatismo\" \n",
            "Ao colocar Deus no centro do discurso, Bolsonaro revela que o eixo fundamentalista ainda é sua principal base eleitoral, o ponto de fôlego da sua narrativa e que expoentes desse fundamentalismo, como o pastor Silas Malafaia, permanecem como financiadores e artífices da extrema direita no país. \n",
            "\n",
            "\n",
            "A fé no centro da narrativa \n",
            "Já passava das 15h do último domingo (25) quando Michelle Bolsonaro começou a discursar no ato em defesa do marido, o ex-presidente Jair Bolsonaro (PL). Para um público vestido com a camisa da seleção brasileira, ela fez um discurso repleto de símbolos religiosos. Emocionada, gritou \"glória a Deus\" diversas vezes, mencionou que Bolsonaro havia sido escolhido para governar o país e conclamou os religiosos a se envolverem com a política.\n",
            "Michelle Bolsonaro trazia estampado no peito um pedido muito comum entre religiosos: \"Ore pelo Brasil'. A ex-primeira-dama, segundo pesquisadores ouvidos pelo Brasil de Fato, é a personagem que representa com mais autenticidade a estética evangélica. Ela vive, de fato, a experiência religiosa que manifesta ao grande público e utiliza uma linguagem facilmente absorvida pela maioria da população periférica e evangélica, em especial as mulheres. \n",
            "\"Sim, por um bom tempo nós fomos negligentes a ponto de falarmos que não poderíamos misturar política com religião e o mal ocupou o espaço\", afirmou a ex-primeira-dama. \n",
            "\"O peso da fala dela é que essa disputa é central hoje com a população. É muito bem utilizada pela Michelle. Ela tem o estereótipo, ela tem a estética crente, né? Ela se movimenta, ela gesticula, ela está a todo momento olhando pro céu, se emociona. É um culto pentecostal\", explicou Delana Corazza. \n",
            "\"Ela está falando de um período contemporâneo, um período presente, em que, nessa consideração, e que é compartilhada por algumas figuras do universo evangélico, é preciso uma presença mais forte, uma interferência maior, para que o Brasil seja definitivamente um Brasil que se renda ao governo de Deus\", aponta Magali Cunha.\r\n",
            " \n",
            "\r\n",
            "Apoiadores de Bolsonaro usam bandeira de Israel durante ato na Avenida Paulista / Lucas Martins (@lucasport01)\n",
            "Israel e o sionismo cristão\n",
            "A defesa do Estado de Israel foi um dos principais temas da manifestação e demonstra que o populismo religioso no Brasil tem uma articulação internacional. Bolsonaro e seus apoiadores tremulavam, ao longo do ato, a bandeira israelense, o que denota a aliança do bolsonarismo com o chamado sionismo cristão, grupo de cristãos evangélicos que apoia o fortalecimento do Estado de Israel. \n",
            "Na semana anterior ao ato, repercutiu a declaração do presidente Lula da Silva condenando o massacre de Israel contra o povo palestino e pedindo o imediato cessar-fogo na Faixa de Gaza. O posicionamento crítico do petista instantaneamente reforçou a postura pró-Israel do bolsonarismo e da extrema direita no Brasil, que historicamente tem uma conexão com o sionismo.\n",
            "\"O sionismo cristão acredita que é na constituição, fortalecimento e segmentação do Estado judeu, do Estado de Israel que estaria se cumprindo a promessa de Deus. Seria uma das fases importantes para a volta do reinado de Deus no mundo. É por isso que, embora pareça estranho, aquela frase daquela senhora, que falou que Israel também é cristão, é porque o sionismo cristão opera nessa linguagem, de que os dois, embora mantenham uma certa diferença, estão de mãos dadas diante do Projeto Divino\", explicou Caio César Marçal, cientista social e teólogo. \n",
            "\"Acho que é fundamental que a gente compreenda que o uso dessa linguagem é mais um signo importante e que unifica o conservadorismo religioso. A gente sabe que o sionismo também tem todo um viés racial, racializado, que trata o diferente como o seu inimigo. Essa linguagem é de um discurso conservador que mantém as estruturas contra as minorias, e aqui a minoria são todos aqueles que são contra a igreja e contra Israel - nesse caso atual, os palestinos\", completa.\n",
            "\r\n",
            "A presença de símbolos religiosos confirma a aposta do bolsonarismo na base conservadora cristã / Lucas Martins (@lucasport01 )\n",
            "Alerta para a esquerda\n",
            "O ato não contou com maioria evangélica entre os manifestantes. Segundo estudo da Universidade de São Paulo, apenas 29% das pessoas presentes se declaravam evangélicas. A maioria, formada por homens  brancos  e  “muito conservadores”, ainda se denominava católica. \n",
            "Os pesquisadores atentam para um ajuste no discurso bolsonarista, quando seus principais atores preferem declarar-se cristãos e não exatamente evangélicos. \n",
            "Além disso, há o entendimento de que a manifestação do último domingo, em São Paulo, não é um movimento desprezível e demonstra que a extrema direita tem um projeto de poder, consegue articular ações de massa no país e impõe uma desafio para as organizações progressistas e de esquerda: refinar o diálogo com a população evangélica.\n",
            "\"A extrema direita aprendeu a mobilizar essa linguagem, ela entendeu que essa linguagem é importante e basicamente também  entendeu as mudanças sociais que acontecem no Brasil. Qual é a grande mudança social no Brasil dos últimos 40 anos? O crescimento exponencial dos evangélicos\", descreve o cientista social Caio César Marçal, sobre o uso político que o bolsonarismo faz do populismo religioso. \n",
            "\"A coesão da extrema direita está vinculada ao discurso religioso, ao debate religioso. Talvez esse ato possa nos ensinar que a gente tem muito trabalho, que o bolsonarismo está forte, que o bolsonarismo é mediado por esse discurso, que é uma linguagem que a gente tem que se apropriar. A gente tem que deixar de ridicularizar e se apropriar\", conclui Delana Corazza\r\n",
            " \n",
            "Edição: Matheus Alves de Almeida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GQdpjJ_p2ViF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "-b2y_9n-3mMd"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar os recursos necessários do NLTK\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxO80Qko3wLW",
        "outputId": "a59d0b09-43ab-49bb-9ea4-10f65fd6e52b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando um conjunto de dados vazio\n",
        "dataset_BdF = []\n",
        "\n",
        "# Tokenizando em frases\n",
        "for paragraph in paragraphs:\n",
        "    sentences_BdF = sent_tokenize(paragraph.get_text())\n",
        "\n",
        "    # Pegando apenas as 5 primeiras frases\n",
        "    for idx, sentence_BdF in enumerate(sentences_BdF[:5], start=1):\n",
        "        dataset_BdF.append(sentence_BdF)\n",
        "\n",
        "    # Verificando se já pegou 5 frases e interrompendo o loop\n",
        "    if len(dataset_BdF) >= 5:\n",
        "        break\n",
        "\n",
        "# Visualizando o conjunto de dados\n",
        "for sentence in dataset_BdF:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9hhJCYK8Rdz",
        "outputId": "91903c01-d8dd-4586-e18d-02000f7352be"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A manifestação em defesa do ex-presidente Jair Bolsonaro (PL), no último domingo(25), em São Paulo, reforçou a tática política adotada pela extrema direita no Brasil do chamado populismo religioso e demonstrou que o bolsonarismo busca sobrevida eleitoral alimentando a base cristã.\n",
            "O ato serviu para manter os apoiadores ligados ao conservadorismo nacional coesos e apontar o tom da disputa política nas eleições municipais.\n",
            "A manifestação, convocada logo após o cerco da Polícia Federal ao ex-presidente, contou com a presença de quatro governadores, deputados e prefeitos, além dos pastores Magno Malta (que também é senador pelo Espírito Santo) e Silas Malafaia, este último apontado como um dos financiadores.\n",
            "Acuado pelas investigações da PF e pela inelegibilidade imposta pelo Tribunal Superior Eleitoral (TSE), Bolsonaro saiu em sua própria defesa, tentou suavizar o seu comportamento anterior e sugeriu passar uma borracha no passado.\n",
            "No lugar dos ataques aos ministros do Supremo Tribunal Federal e as demais instituições da república, um apelo à anistia aos envolvidos no oito de janeiro e a defesa do Estado Democrático de Direito.\n",
            "O ato na Avenida Paulista acabou tomado pela estética religiosa, com repetidas citações bíblicas, louvor cristão como trilha sonora e discurso de dois pastores evangélicos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um novo conjunto de dados com palavras mascaradas\n",
        "masked_BdF = [mask_words(sentence) for sentence in dataset_BdF]\n",
        "\n",
        "# Visualizando o conjunto de dados mascarado\n",
        "for sentence_BdF in masked_BdF:\n",
        "    print(sentence_BdF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLbiBk362Wd_",
        "outputId": "d35fade6-b144-4c4b-e1d5-9c51fe353121"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A manifestação em defesa do ex-presidente [MASK] Bolsonaro (PL), no último domingo(25), em São Paulo, reforçou a tática política [MASK] pela extrema direita no Brasil do [MASK] populismo religioso e demonstrou que o [MASK] busca sobrevida eleitoral [MASK] [MASK] base cristã.\n",
            "[MASK] ato serviu para manter [MASK] apoiadores ligados [MASK] conservadorismo nacional coesos e apontar o tom da disputa política nas eleições municipais.\n",
            "A manifestação, convocada logo após o cerco da Polícia Federal [MASK] ex-presidente, contou com [MASK] presença [MASK] quatro governadores, deputados e [MASK] além dos pastores Magno Malta (que também é senador pelo Espírito [MASK] e Silas Malafaia, este último apontado como [MASK] dos financiadores.\n",
            "Acuado pelas investigações da PF e pela [MASK] imposta pelo Tribunal Superior Eleitoral (TSE), Bolsonaro saiu em sua própria [MASK] tentou suavizar o seu comportamento anterior e [MASK] passar uma [MASK] no passado.\n",
            "No [MASK] dos ataques aos ministros do [MASK] Tribunal Federal e as demais [MASK] da república, um apelo à anistia aos envolvidos no oito de janeiro [MASK] [MASK] defesa do Estado Democrático de Direito.\n",
            "O ato na Avenida [MASK] acabou tomado pela estética religiosa, com [MASK] citações bíblicas, louvor cristão como trilha sonora [MASK] discurso de dois pastores evangélicos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de sentenças\n",
        "sentences = masked_BdF\n",
        "\n",
        "# Tokenize as sentenças e substitua uma palavra por [MASK]\n",
        "tokenized_sentences_BdF = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "print(\"Sentenças tokenizadas:\", tokenized_sentences_BdF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icdaTSIp9vZ-",
        "outputId": "c9ff6206-0fa4-49cf-9165-c5febf015d6b"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentenças tokenizadas: {'input_ids': tensor([[  101,   177, 11926,   173,  3573,   171,   294,   118,  1640,   103,\n",
            "         20354,   716,   157,   113,   212, 22327,   114,   117,   202,  1957,\n",
            "         11388,   113,  1906,   114,   117,   173,   710,  1033,   117, 14776,\n",
            "         22288,   123, 19545,  1837,   103,   412,  4493,  5065,   202,   771,\n",
            "           171,   103, 12936,   714,  7255,   122, 12219,   179,   146,   103,\n",
            "          3344,  3051,   328,  8629,   103,   103,  1037,  7216,   119,   102],\n",
            "        [  101,   103,  5291,  5083,   221,  3247,   103, 11781,   207,  8642,\n",
            "           103, 14992,   714,  1772, 14336,  1409,   122, 12110, 22282,   146,\n",
            "          5902,   180,  3623,  1837,   529,  3496,  9057,   119,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   177, 11926,   117,  4813,  2382,  2044,   790,   146,  8810,\n",
            "           180,  6219,  2528,   103,   294,   118,  1640,   117,  5222,   170,\n",
            "           103,  2645,   103,  1256, 17448,   117,  9256,   122,   103,  1166,\n",
            "           298, 20961, 13352, 16435,   113,   179,   407,   253,  7347,   423,\n",
            "          6467,   103,   122,  2057,   138, 13184,  1165,   151,   117,   860,\n",
            "          1957, 15798,   271,   103,   298,  9309,  2247,   119,   102,     0],\n",
            "        [  101,  1980,  3611,   243,  1676, 11864,   180,   212, 22324,   122,\n",
            "           412,   103,  6529,   154,   423,  4846,  5962, 10904,   113,   267,\n",
            "         13925,   114,   117, 20354,   716,   157,  5127,   173,   327,  2288,\n",
            "           103,  4646,   327,   419,  4803,   146,   347,  4997,  2095,   122,\n",
            "           103,  3852,   230,   103,   202,  3714,   119,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   409,   103,   298,  4642,   712, 12058,   171,   103,  4846,\n",
            "          2528,   122,   260,  3547,   103,   180,  9844,   117,   222, 15552,\n",
            "           353,   360,  4681,   712,  8612,   202,  3003,   125,  1543,   103,\n",
            "           103,  3573,   171,  1477, 12419,   125,  4220,   119,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   231,  5291,   229,  6382,   103,  2467, 12585,   412, 13244,\n",
            "          5936,   117,   170,   103, 12374,   315,  9813,   585,   117,  7406,\n",
            "          2248,  9665,   271,  5240,  5276,   103,  6789,   125,   682, 20961,\n",
            "          7379, 18341,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acesse os IDs dos tokens\n",
        "input_ids_BdF = tokenized_sentences_BdF[\"input_ids\"]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuOPJlVb-OwV",
        "outputId": "62a815fb-cb62-4c0d-ed79-c82acea38a71"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 101,  510,  103,  453, 3155, 8573,  387,  358,  119,  102],\n",
            "        [ 101,  103,  698,  202, 1997,  180,  651,  119,  102,    0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask_BdF = tokenized_sentences_BdF['attention_mask']\n",
        "print(attention_mask_BdF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7i_2Iuz-Z0q",
        "outputId": "7757d9c9-bed9-4e14-e416-89540e103d52"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_BdF = input_ids_BdF.clone()\n",
        "print(labels_BdF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWUa81u4-mJz",
        "outputId": "536c9034-476e-433e-a463-1ba44c146831"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,   177, 11926,   173,  3573,   171,   294,   118,  1640,   103,\n",
            "         20354,   716,   157,   113,   212, 22327,   114,   117,   202,  1957,\n",
            "         11388,   113,  1906,   114,   117,   173,   710,  1033,   117, 14776,\n",
            "         22288,   123, 19545,  1837,   103,   412,  4493,  5065,   202,   771,\n",
            "           171,   103, 12936,   714,  7255,   122, 12219,   179,   146,   103,\n",
            "          3344,  3051,   328,  8629,   103,   103,  1037,  7216,   119,   102],\n",
            "        [  101,   103,  5291,  5083,   221,  3247,   103, 11781,   207,  8642,\n",
            "           103, 14992,   714,  1772, 14336,  1409,   122, 12110, 22282,   146,\n",
            "          5902,   180,  3623,  1837,   529,  3496,  9057,   119,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   177, 11926,   117,  4813,  2382,  2044,   790,   146,  8810,\n",
            "           180,  6219,  2528,   103,   294,   118,  1640,   117,  5222,   170,\n",
            "           103,  2645,   103,  1256, 17448,   117,  9256,   122,   103,  1166,\n",
            "           298, 20961, 13352, 16435,   113,   179,   407,   253,  7347,   423,\n",
            "          6467,   103,   122,  2057,   138, 13184,  1165,   151,   117,   860,\n",
            "          1957, 15798,   271,   103,   298,  9309,  2247,   119,   102,     0],\n",
            "        [  101,  1980,  3611,   243,  1676, 11864,   180,   212, 22324,   122,\n",
            "           412,   103,  6529,   154,   423,  4846,  5962, 10904,   113,   267,\n",
            "         13925,   114,   117, 20354,   716,   157,  5127,   173,   327,  2288,\n",
            "           103,  4646,   327,   419,  4803,   146,   347,  4997,  2095,   122,\n",
            "           103,  3852,   230,   103,   202,  3714,   119,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   409,   103,   298,  4642,   712, 12058,   171,   103,  4846,\n",
            "          2528,   122,   260,  3547,   103,   180,  9844,   117,   222, 15552,\n",
            "           353,   360,  4681,   712,  8612,   202,  3003,   125,  1543,   103,\n",
            "           103,  3573,   171,  1477, 12419,   125,  4220,   119,   102,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   231,  5291,   229,  6382,   103,  2467, 12585,   412, 13244,\n",
            "          5936,   117,   170,   103, 12374,   315,  9813,   585,   117,  7406,\n",
            "          2248,  9665,   271,  5240,  5276,   103,  6789,   125,   682, 20961,\n",
            "          7379, 18341,   119,   102,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar DataLoader\n",
        "dataset2 = TensorDataset(input_ids_BdF, attention_mask_BdF, labels_BdF)\n",
        "train_size = int(0.8 * len(dataset2))\n",
        "val_size = len(dataset2) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset2, [train_size, val_size])\n",
        "\n",
        "train_dataloader_BdF = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "EMaMBzSY-ofn"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_dataloader_BdF, optimizer, scheduler, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovc-Ol99-ob_",
        "outputId": "aa5a8d4e-2de2-46a1-df42-bcbcd200c775"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 4.095005393028259\n",
            "Epoch 2/10, Average Loss: 3.903255581855774\n",
            "Epoch 3/10, Average Loss: 3.9597092866897583\n",
            "Epoch 4/10, Average Loss: 3.837762951850891\n",
            "Epoch 5/10, Average Loss: 3.8998477458953857\n",
            "Epoch 6/10, Average Loss: 4.122880697250366\n",
            "Epoch 7/10, Average Loss: 3.892215847969055\n",
            "Epoch 8/10, Average Loss: 3.917101740837097\n",
            "Epoch 9/10, Average Loss: 3.9680938720703125\n",
            "Epoch 10/10, Average Loss: 3.8386093378067017\n"
          ]
        }
      ]
    }
  ]
}